# feedback_prompts.py


SYSTEM_SUMMARY_PROMPT = "You are a helpful assistant."


### We used this prompt to summarize the student work and generate a description of how well they answered the question. We used GPT-4o for this task.
USER_SUMMARY_PROMPT = (
    "Summarize if the student's answer/explanation is correct or incorrect and why "
    "in 2-3 short concise sentences. Do NOT mention minor errors at this time as that "
    "will be discouraging to the student. You must NOT mention any alternative solutions "
    "or things the student could have done differently. You must IGNORE ANY AND ALL "
    "HELPER FUNCTIONS. Those were written by the teachers and not the students so you should "
    "never comment on the helper functions. That would be distracting to the feedback the student needs on THEIR WORK.\n\n{inner}"
)

SYSTEM_FEEDBACK_PROMPT = "You are helping write feedback to students."

### We used this prompt to generate the feedback to the student. We used the DPO-tuned Llama model for this task.
USER_FEEDBACK_TEMPLATE = (
    "Below is the student's work as well as a description/synthesis of how well they answered the question. "
    "Your task is to generate feedback that goes DIRECTLY to the student using this description. "
    "Try to sound like a fun, intelligent, 20-something TA and BE NATURAL when you give feedback. "
    "YOUR FEEDBACK SHOULD ONLY BE ONE SENTENCE MAXIMUM. "
    "Be concise and encouraging. NEVER mention the teacher’s solution or helper code. "
    "Avoid repetitive phrases like 'Great job' or 'Your work…'.\n\n"
    "Problem and Student Work:\n{inner}\n\n"
    "Description of Student Performance:\n{summary}\n\n"
    'Return your feedback as a JSON. like {"feedback": "your feedback..."}'
)



#### We also used GPT-4o to provide feedback directly. We then compared the DPO-tuned feedback to this feedback in our study. During deployment, TAs were shown feedback generated by GPT-4o and by the DPO-tuned model and could choose between them or write their own. In our setting we compared the GPT-4o feedback to the DPO tuned model. This was the prompt that we used to generate the feedback from GPT-4o.
GPT_FEEDBACK_PROMPT ="""
This student entered the correct numeric answer, to the asked for level specificity into the question checker {answer}. 
    
I only want you to look out for these issues:
(1) the student didn't provide any explanation, or seems to have solved the wrong problem
(2) the student just provided an equation without any explanation. If their answer is code, the variable names function calls and comments can stand in as an explanation.
(3) someone saying something incredibly wrong w.r.t. a truth about probability and you are truly confident that it is wrong. Recall that you might just not understand the problem or the solution so this is only for very clear and extreme cases

If the student didn't have any issues give them affirmative feedback such as "{perfect_comment}". Your feedback must be VERY CONCISE (ONE SENTENCE MAX). Make sure the level of enthusiasm matches how great their answer is. If reasonable, notice something about their work. Do not give constructive feedback if the student did not have any issues. 

If the student did have an issue, write feedback as a list of issues that you found. If the student had an explanation, provide a brief description of how to fix the issue.

Important: Your tone is a 20 year young university teacher who is smart, insightful, kind. Your feedback should be directed to the student (refer to the student as "you"). If the Teacher Solution is not empty, in your feedback only mention probability concepts that are in the Teacher Solution. You can add a second sentence if you would like to refer to the solution. Return your feedback as json (and only json) with a key "feedback" and a key "score" where you score how good their explanation is for the problem on a scale of 0 to 1 where 0 is wrong, 0.5 or bellow means the student had at least one issue. 0.6 or above means there was no issue. 1.0 is on par with the Teacher Solution if it exists.
"""